{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Val Metrics\n",
    "### PSNR + SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import torch\n",
    "import kornia.metrics as km\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- CONFIG ----\n",
    "VIS_DIR = Path(\"/teamspace/studios/this_studio/neosr/experiments/train_plksr_3x/visualization\")  # visualization folder with all frames\n",
    "GT_DIR = Path(\"/teamspace/studios/upres-ml-dataset-small/sr_dataset/3_0x/val/HR\")          # ground truth images\n",
    "\n",
    "MODEL_NAME = \"plksr\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_tensorize(path):\n",
    "    img = cv2.imread(str(path), cv2.IMREAD_COLOR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = torch.from_numpy(img).permute(2, 0, 1).float() / 255.0  # [C, H, W]\n",
    "    return img\n",
    "\n",
    "def chunked(iterable, size):\n",
    "    for i in range(0, len(iterable), size):\n",
    "        yield iterable[i:i + size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Step 1: collect all SR-GT pairs grouped by checkpoint step\n",
    "    pairs = []\n",
    "    for frame_dir in tqdm(list(VIS_DIR.iterdir()), desc=\"Scanning frame folders\"):\n",
    "        if not frame_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        frame_name = frame_dir.name\n",
    "        gt_path = GT_DIR / f\"{frame_name}.png\"\n",
    "        if not gt_path.exists():\n",
    "            continue\n",
    "\n",
    "        for sr_file in frame_dir.glob(f\"{frame_name}_*.png\"):\n",
    "            if \"_lq.png\" in sr_file.name:\n",
    "                continue\n",
    "\n",
    "            match = re.search(rf\"{frame_name}_(\\d+)\\.png\", sr_file.name)\n",
    "            if match:\n",
    "                step = int(match.group(1))\n",
    "                pairs.append((step, sr_file, gt_path))\n",
    "\n",
    "    step_to_pairs = defaultdict(list)\n",
    "    for step, sr_path, gt_path in pairs:\n",
    "        step_to_pairs[step].append((sr_path, gt_path))\n",
    "\n",
    "    print(f\"\\nðŸ“Š Checkpoints found: {len(step_to_pairs)}\")\n",
    "\n",
    "   # Step 2: batched PSNR & SSIM on GPU with chunking\n",
    "    results = []\n",
    "    batch_size = 8  # you can increase if memory allows\n",
    "\n",
    "    for step in tqdm(sorted(step_to_pairs.keys()), desc=\"Evaluating checkpoints\"):\n",
    "        sr_tensors = []\n",
    "        gt_tensors = []\n",
    "\n",
    "        for sr_path, gt_path in step_to_pairs[step]:\n",
    "            try:\n",
    "                sr_tensor = read_and_tensorize(sr_path)\n",
    "                gt_tensor = read_and_tensorize(gt_path)\n",
    "\n",
    "                if sr_tensor.shape != gt_tensor.shape:\n",
    "                    raise ValueError(f\"Shape mismatch: {sr_path.name}\")\n",
    "\n",
    "                sr_tensors.append(sr_tensor)\n",
    "                gt_tensors.append(gt_tensor)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {sr_path.name}: {e}\")\n",
    "                continue\n",
    "\n",
    "        if not sr_tensors or not gt_tensors:\n",
    "            continue\n",
    "\n",
    "        psnrs, ssims = [], []\n",
    "        for sr_chunk, gt_chunk in zip(chunked(sr_tensors, batch_size), chunked(gt_tensors, batch_size)):\n",
    "            try:\n",
    "                sr_batch = torch.stack(sr_chunk).to(DEVICE)\n",
    "                gt_batch = torch.stack(gt_chunk).to(DEVICE)\n",
    "\n",
    "                psnr_val = km.psnr(sr_batch, gt_batch, 1.0).mean().item()\n",
    "                ssim_val = km.ssim(sr_batch, gt_batch, 11).mean().item()\n",
    "\n",
    "                psnrs.append(psnr_val)\n",
    "                ssims.append(ssim_val)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in chunked PSNR/SSIM for step {step}: {e}\")\n",
    "                continue\n",
    "\n",
    "        if psnrs and ssims:\n",
    "            results.append({\n",
    "                \"checkpoint_step\": step,\n",
    "                \"avg_psnr\": np.mean(psnrs),\n",
    "                \"avg_ssim\": np.mean(ssims),\n",
    "                \"num_images\": len(sr_tensors)\n",
    "            })\n",
    "\n",
    "    # Step 3: save results\n",
    "    df = pd.DataFrame(results).sort_values(\"checkpoint_step\")\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d\")\n",
    "    output_csv = f\"{MODEL_NAME}_val_metrics_{timestamp}_{len(results)}ckpts.csv\"\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\nâœ… Saved results to: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your results CSV\n",
    "df = pd.read_csv(\"plksr_val_metrics_20250416_49ckpts.csv\")  # update name if different\n",
    "\n",
    "# Sort by checkpoint_step (just in case)\n",
    "df = df.sort_values(\"checkpoint_step\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(df[\"checkpoint_step\"], df[\"avg_psnr\"], label=\"PSNR\", marker=\"o\")\n",
    "plt.plot(df[\"checkpoint_step\"], df[\"avg_ssim\"], label=\"SSIM\", marker=\"s\")\n",
    "\n",
    "plt.title(\"PLKSR Validation Metrics Avg by Checkpoint Step\")\n",
    "plt.xlabel(\"Checkpoint Step\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"psnr_ssim_plot.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"psnr_ssim_plot.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your PSNR/SSIM CSV\n",
    "df = pd.read_csv(\"./plksr_val_metrics_20250416_49ckpts.csv\")\n",
    "\n",
    "# Best PSNR\n",
    "best_psnr_idx = df[\"avg_psnr\"].idxmax()\n",
    "best_psnr_step = df.loc[best_psnr_idx, \"checkpoint_step\"]\n",
    "best_psnr_value = df.loc[best_psnr_idx, \"avg_psnr\"]\n",
    "\n",
    "# Best SSIM\n",
    "best_ssim_idx = df[\"avg_ssim\"].idxmax()\n",
    "best_ssim_step = df.loc[best_ssim_idx, \"checkpoint_step\"]\n",
    "best_ssim_value = df.loc[best_ssim_idx, \"avg_ssim\"]\n",
    "\n",
    "# Report results\n",
    "print(\"For PLKSR: \")\n",
    "print(f\"ðŸ“ˆ Best PSNR:  {best_psnr_value:.4f} at step {best_psnr_step}\")\n",
    "print(f\"ðŸ“ˆ Best SSIM:  {best_ssim_value:.4f} at step {best_ssim_step}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your PSNR/SSIM CSV\n",
    "df = pd.read_csv(\"./real_plksr_val_metrics_20250417_42ckpts.csv\")\n",
    "\n",
    "# Best PSNR\n",
    "best_psnr_idx = df[\"avg_psnr\"].idxmax()\n",
    "best_psnr_step = df.loc[best_psnr_idx, \"checkpoint_step\"]\n",
    "best_psnr_value = df.loc[best_psnr_idx, \"avg_psnr\"]\n",
    "\n",
    "# Best SSIM\n",
    "best_ssim_idx = df[\"avg_ssim\"].idxmax()\n",
    "best_ssim_step = df.loc[best_ssim_idx, \"checkpoint_step\"]\n",
    "best_ssim_value = df.loc[best_ssim_idx, \"avg_ssim\"]\n",
    "\n",
    "# Report results\n",
    "print(\"For RealPLKSR: \")\n",
    "print(f\"ðŸ“ˆ Best PSNR:  {best_psnr_value:.4f} at step {best_psnr_step}\")\n",
    "print(f\"ðŸ“ˆ Best SSIM:  {best_ssim_value:.4f} at step {best_ssim_step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
